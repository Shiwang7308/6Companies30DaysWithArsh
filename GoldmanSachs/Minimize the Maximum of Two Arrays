https://leetcode.com/problems/minimize-the-maximum-of-two-arrays/description/

class Solution {
public:
    int minimizeSet(long long div1, long long div2, int cnt1, int cnt2)
    {
        long long lcm = (div1 * div2) / __gcd(div1, div2);
        long long total = cnt1 + cnt2;
        long long l = total, r = 1e12;
        long long ans = 0;
        while (l <= r)
        {
            long long mid = (l + r) / 2;
            long long both = mid / lcm;
            long long onlyA = mid / div2 - both;
            long long onlyB = mid / div1 - both;
            total = max(0ll, cnt1 - onlyA) + max(0ll, cnt2 - onlyB);
            if (mid - onlyA - onlyB >= total + both)
            {
                ans = mid;
                r = mid - 1;
            }
            else
                l = mid + 1;
        }
        return ans;
    }
};

Explanation
The minimum possible answer is UniqueCnt1 + UniqueCnt2.
The values which are divisible by both divisor1 and divisor2 need to be added to the required total.
(This is stored in both)

The values which are multiple of divisor2 and not a multiple of divisor1 will be reserved for UniqueCnt1.
(This is stored in OnlyA)

The values which are multiple of divisor1 and not a multiple of divisor2 will be reserved for UniqueCnt2.
(This is stored in OnlyB)

Now the total remaining value are ONLY THOSE which are neither multiple of divisor1 nor multiple of divisor2.
(This is store in total)